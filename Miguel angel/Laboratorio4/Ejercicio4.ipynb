{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2886c73-a3a8-4784-b7a8-56a8507f4786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Sepal Length  Sepal Width  Petal Length  Petal Width      Species\n",
      "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
      "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
      "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
      "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
      "4           5.0          3.6           1.4          0.2  Iris-setosa\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Sepal Length  150 non-null    float64\n",
      " 1   Sepal Width   150 non-null    float64\n",
      " 2   Petal Length  150 non-null    float64\n",
      " 3   Petal Width   150 non-null    float64\n",
      " 4   Species       150 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n",
      "None\n",
      "Accuracy del Árbol de Decisión: 1.0\n",
      "Accuracy de KNN: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Protoss\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy de Red Neuronal: 1.0\n",
      "Accuracy del ensemble usando Boosting: 1.0\n",
      "Accuracy del ensemble usando VotingClassifier: 1.0\n",
      "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Protoss\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Protoss\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:547: FitFailedWarning: \n",
      "540 fits failed out of a total of 1620.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "436 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Protoss\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Protoss\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\Protoss\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\Protoss\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of DecisionTreeClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "104 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Protoss\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Protoss\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\Protoss\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\Protoss\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of DecisionTreeClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Protoss\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.90833333 0.9        0.9\n",
      " 0.91666667 0.925      0.925      0.925      0.925      0.925\n",
      " 0.90833333 0.9        0.9        0.91666667 0.925      0.925\n",
      " 0.925      0.925      0.925             nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.90833333 0.9        0.9        0.91666667 0.925      0.925\n",
      " 0.925      0.925      0.925      0.90833333 0.9        0.9\n",
      " 0.91666667 0.925      0.925      0.925      0.925      0.925\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.90833333 0.9        0.9\n",
      " 0.91666667 0.925      0.925      0.925      0.925      0.925\n",
      " 0.90833333 0.9        0.9        0.91666667 0.925      0.925\n",
      " 0.925      0.925      0.925             nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.90833333 0.9        0.9        0.91666667 0.925      0.925\n",
      " 0.925      0.925      0.925      0.90833333 0.9        0.9\n",
      " 0.91666667 0.925      0.925      0.925      0.925      0.925\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.90833333 0.9        0.9\n",
      " 0.91666667 0.925      0.925      0.925      0.925      0.925\n",
      " 0.90833333 0.9        0.9        0.91666667 0.925      0.925\n",
      " 0.925      0.925      0.925             nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.90833333 0.9        0.9        0.91666667 0.925      0.925\n",
      " 0.925      0.925      0.925      0.90833333 0.9        0.9\n",
      " 0.91666667 0.925      0.925      0.925      0.925      0.925\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.925      0.91666667 0.925\n",
      " 0.91666667 0.925      0.925      0.925      0.925      0.925\n",
      " 0.925      0.91666667 0.925      0.91666667 0.925      0.925\n",
      " 0.925      0.925      0.925             nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.925      0.91666667 0.925      0.91666667 0.925      0.925\n",
      " 0.925      0.925      0.925      0.925      0.91666667 0.925\n",
      " 0.91666667 0.925      0.925      0.925      0.925      0.925\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.925      0.91666667 0.925\n",
      " 0.91666667 0.925      0.925      0.925      0.925      0.925\n",
      " 0.925      0.91666667 0.925      0.91666667 0.925      0.925\n",
      " 0.925      0.925      0.925             nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.925      0.91666667 0.925      0.91666667 0.925      0.925\n",
      " 0.925      0.925      0.925      0.925      0.91666667 0.925\n",
      " 0.91666667 0.925      0.925      0.925      0.925      0.925\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.925      0.91666667 0.925\n",
      " 0.91666667 0.925      0.925      0.925      0.925      0.925\n",
      " 0.925      0.91666667 0.925      0.91666667 0.925      0.925\n",
      " 0.925      0.925      0.925             nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.925      0.91666667 0.925      0.91666667 0.925      0.925\n",
      " 0.925      0.925      0.925      0.925      0.91666667 0.925\n",
      " 0.91666667 0.925      0.925      0.925      0.925      0.925     ]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor combinación de parámetros para Árbol de Decisión: {'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 5}\n",
      "Accuracy del mejor modelo de Árbol de Decisión: 0.9666666666666667\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Mejor combinación de parámetros para KNN: {'metric': 'manhattan', 'n_neighbors': 14, 'weights': 'uniform'}\n",
      "Accuracy del mejor modelo de KNN: 1.0\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "Mejor combinación de parámetros para Red Neuronal: {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "Accuracy del mejor modelo de Red Neuronal: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Protoss\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from scipy.stats import randint\n",
    "import numpy as np\n",
    "\n",
    "# Cargar los datos\n",
    "\n",
    "data = pd.read_csv('iris-data.csv')\n",
    "\n",
    "# Visualizar las primeras filas y la estructura de los datos\n",
    "print(data.head())\n",
    "print(data.info())\n",
    "\n",
    "X = data.drop('Species', axis=1)  # Features\n",
    "y = data['Species']  # Target variable\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenar modelo de Árbol de Decisión\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar modelo de Árbol de Decisión\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "acc_dt = accuracy_score(y_test, y_pred_dt)\n",
    "print(\"Accuracy del Árbol de Decisión:\", acc_dt)\n",
    "\n",
    "# Entrenar modelo KNN\n",
    "knn_model = KNeighborsClassifier()\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar modelo KNN\n",
    "y_pred_knn = knn_model.predict(X_test)\n",
    "acc_knn = accuracy_score(y_test, y_pred_knn)\n",
    "print(\"Accuracy de KNN:\", acc_knn)\n",
    "\n",
    "# Entrenar modelo Red Neuronal\n",
    "mlp_model = MLPClassifier(random_state=42)\n",
    "mlp_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar modelo Red Neuronal\n",
    "y_pred_mlp = mlp_model.predict(X_test)\n",
    "acc_mlp = accuracy_score(y_test, y_pred_mlp)\n",
    "print(\"Accuracy de Red Neuronal:\", acc_mlp)\n",
    "\n",
    "# Crear ensemble usando Boosting\n",
    "ensemble_boosting = GradientBoostingClassifier(random_state=42)\n",
    "ensemble_boosting.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar ensemble usando Boosting\n",
    "y_pred_boosting = ensemble_boosting.predict(X_test)\n",
    "acc_boosting = accuracy_score(y_test, y_pred_boosting)\n",
    "print(\"Accuracy del ensemble usando Boosting:\", acc_boosting)\n",
    "\n",
    "# Crear ensemble usando VotingClassifier\n",
    "ensemble_voting = VotingClassifier(estimators=[\n",
    "    ('dt', dt_model),\n",
    "    ('knn', knn_model),\n",
    "    ('mlp', mlp_model)\n",
    "], voting='hard')\n",
    "ensemble_voting.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar ensemble usando VotingClassifier\n",
    "y_pred_voting = ensemble_voting.predict(X_test)\n",
    "acc_voting = accuracy_score(y_test, y_pred_voting)\n",
    "print(\"Accuracy del ensemble usando VotingClassifier:\", acc_voting)\n",
    "\n",
    "# Definir espacio de búsqueda de parámetros\n",
    "param_grid_dt = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Instanciar GridSearchCV\n",
    "grid_search_dt = GridSearchCV(estimator=DecisionTreeClassifier(random_state=42),\n",
    "                              param_grid=param_grid_dt,\n",
    "                              scoring='accuracy',\n",
    "                              cv=5,\n",
    "                              verbose=1,\n",
    "                              n_jobs=-1)\n",
    "grid_search_dt.fit(X_train, y_train)\n",
    "\n",
    "# Mejor combinación de parámetros\n",
    "best_params_dt = grid_search_dt.best_params_\n",
    "print(\"Mejor combinación de parámetros para Árbol de Decisión:\", best_params_dt)\n",
    "\n",
    "# Evaluación del mejor modelo\n",
    "best_dt_model = grid_search_dt.best_estimator_\n",
    "y_pred_best_dt = best_dt_model.predict(X_test)\n",
    "acc_best_dt = accuracy_score(y_test, y_pred_best_dt)\n",
    "print(\"Accuracy del mejor modelo de Árbol de Decisión:\", acc_best_dt)\n",
    "\n",
    "# Definir espacio de búsqueda de parámetros\n",
    "param_dist_knn = {\n",
    "    'n_neighbors': randint(1, 20),\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "# Instanciar RandomizedSearchCV\n",
    "random_search_knn = RandomizedSearchCV(estimator=KNeighborsClassifier(),\n",
    "                                       param_distributions=param_dist_knn,\n",
    "                                       n_iter=100,\n",
    "                                       scoring='accuracy',\n",
    "                                       cv=5,\n",
    "                                       verbose=1,\n",
    "                                       n_jobs=-1,\n",
    "                                       random_state=42)\n",
    "random_search_knn.fit(X_train, y_train)\n",
    "\n",
    "# Mejor combinación de parámetros\n",
    "best_params_knn = random_search_knn.best_params_\n",
    "print(\"Mejor combinación de parámetros para KNN:\", best_params_knn)\n",
    "\n",
    "# Evaluación del mejor modelo\n",
    "best_knn_model = random_search_knn.best_estimator_\n",
    "y_pred_best_knn = best_knn_model.predict(X_test)\n",
    "acc_best_knn = accuracy_score(y_test, y_pred_best_knn)\n",
    "print(\"Accuracy del mejor modelo de KNN:\", acc_best_knn)\n",
    "\n",
    "# Definir espacio de búsqueda de parámetros\n",
    "param_grid_mlp = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (150,), (200,)],\n",
    "    'activation': ['relu', 'tanh', 'logistic'],\n",
    "    'solver': ['adam', 'sgd'],\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    'learning_rate': ['constant', 'adaptive']\n",
    "}\n",
    "\n",
    "# Instanciar GridSearchCV\n",
    "grid_search_mlp = GridSearchCV(estimator=MLPClassifier(random_state=42),\n",
    "                               param_grid=param_grid_mlp,\n",
    "                               scoring='accuracy',\n",
    "                               cv=5,\n",
    "                               verbose=1,\n",
    "                               n_jobs=-1)\n",
    "grid_search_mlp.fit(X_train, y_train)\n",
    "\n",
    "# Mejor combinación de parámetros\n",
    "best_params_mlp = grid_search_mlp.best_params_\n",
    "print(\"Mejor combinación de parámetros para Red Neuronal:\", best_params_mlp)\n",
    "\n",
    "# Evaluación del mejor modelo\n",
    "best_mlp_model = grid_search_mlp.best_estimator_\n",
    "y_pred_best_mlp = best_mlp_model.predict(X_test)\n",
    "acc_best_mlp = accuracy_score(y_test, y_pred_best_mlp)\n",
    "print(\"Accuracy del mejor modelo de Red Neuronal:\", acc_best_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46adcae7-e471-41a9-b5ee-3a427fc70616",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
